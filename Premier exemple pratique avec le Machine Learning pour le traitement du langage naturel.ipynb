{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Premier exemple pratique avec le Machine Learning pour le traitement du langage naturel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Un exemple rapide : la prédiction du genre du nom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Supposons que nous ayons collecté une liste de noms personnels et que nous ayons leurs étiquettes de genre correspondantes, c'est-à-dire si le nom est masculin ou féminin.\n",
    "\n",
    "Le but de cet exemple est de créer un classificateur qui classerait automatiquement un prénom en masculin ou féminin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des outils et bibliothèques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation des outils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Installation de Python\n",
    "\n",
    "2. Installation de Anaconda\n",
    "\n",
    "Pour plus de détails sur l'installation de ces deux outils, vous pouvez suivre notre vidéo YouTube. Source: https://www.youtube.com/watch?v=Qef4GESFM0I&ab_channel=OnesimeMb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Numpy\n",
    "!pip install nltk.corpus.names\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Préparer les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Nous utilisons les données fournies dans NLTK. Veuillez télécharger les données du corpus si nécessaire.\n",
    "- Nous chargeons le corpus, `nltk.corpus.names` et le randomisons avant de continuer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to C:\\Users\\Onesime\n",
      "[nltk_data]     Mb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "                 [(name, 'female') for name in names.words('female.txt')])\n",
    "random.shuffle(etiquettes_noms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Feature Engineering ou Ingénierie des fonctionnalités"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Maintenant, notre unité de classification est un nom.\n",
    "- En **ingénierie de fonctionnalités**, notre objectif est de transformer les textes (c'est-à-dire les noms) en représentations vectorisées.\n",
    "- Pour commencer, représentons chaque texte (nom) en utilisant son dernier caractère comme caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dernière lettre': 'e'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorisation_texte(mot):\n",
    "    return {'dernière lettre': mot[-1]}\n",
    "\n",
    "\n",
    "vectorisation_texte('Onesime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Division de Jeu de donnees en Train-Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Nous appliquons ensuite la méthode d'ingénierie des fonctionnalités à chaque texte des données et divisons les données en **Training** et **test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "featuresets = [(vectorisation_texte(n), gender) for (n, gender) in etiquettes_noms]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### Entrainement du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Un bon début est d'essayer le simple classificateur Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "classificateur = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male\n",
      "male\n",
      "female\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "print(classificateur.classify(vectorisation_texte('Eric')))\n",
    "print(classificateur.classify(vectorisation_texte('Patrick')))\n",
    "print(classificateur.classify(vectorisation_texte('Aimee')))\n",
    "print(classificateur.classify(vectorisation_texte('Tina')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classificateur, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Analyse post-hoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- L'une des étapes les plus importantes après la formation du modèle consiste à examiner quelles caractéristiques contribuent le plus à la prédiction du classificateur de la classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         dernière lettre = 'a'            female : male   =     35.4 : 1.0\n",
      "         dernière lettre = 'k'              male : female =     31.5 : 1.0\n",
      "         dernière lettre = 'p'              male : female =     20.0 : 1.0\n",
      "         dernière lettre = 'f'              male : female =     16.1 : 1.0\n",
      "         dernière lettre = 'v'              male : female =     10.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classificateur.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Veuillez noter que dans **NLTK**, nous pouvons utiliser **apply_features** pour créer des ensembles Training et de teste.\n",
    "- Lorsque vous disposez d'un très grand ensemble de fonctionnalités, cela peut être plus efficace en termes de gestion de la mémoire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Il s'agit de notre précédente méthode de création d'ensembles de formation et de test :\n",
    "\n",
    "```\n",
    "featuresets = [(vectorisation_texte(n), gender) for (n, gender) in etiquettes_noms]\n",
    "train_set, test_set = featuresets[500:], featuresets[:500]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.classify import apply_features\n",
    "train_set = apply_features(vectorisation_texte, etiquettes_noms[500:])\n",
    "test_set = apply_features(vectorisation_texte, etiquettes_noms[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Comment pouvons-nous améliorer le modèle/classificateur ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dans ce qui suit, nous parlerons des méthodes que nous pourrions envisager pour améliorer davantage la formation du modèle.\n",
    "\n",
    "- Ingénierie des fonctionnalités\n",
    "- Erreur d'analyse\n",
    "- Validation croisée\n",
    "- Essayez différents algorithmes d'apprentissage automatique\n",
    "- (Méthodes d'ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ingénierie de fonctionnalités plus avancée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Nous pouvons extraire plus de fonctionnalités des noms.\n",
    "- Utilisez les fonctionnalités suivantes pour les représentations vectorisées des noms :\n",
    "     - La première/dernière lettre\n",
    "     - Fréquences des 26 alphabets dans les noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'c',\n",
       " 'last_letter': 'e',\n",
       " 'count(a)': 1,\n",
       " 'has(a)': True,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 1,\n",
       " 'has(c)': True,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 1,\n",
       " 'has(e)': True,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 0,\n",
       " 'has(h)': False,\n",
       " 'count(i)': 0,\n",
       " 'has(i)': False,\n",
       " 'count(j)': 0,\n",
       " 'has(j)': False,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 2,\n",
       " 'has(l)': True,\n",
       " 'count(m)': 0,\n",
       " 'has(m)': False,\n",
       " 'count(n)': 0,\n",
       " 'has(n)': False,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 1,\n",
       " 'has(r)': True,\n",
       " 'count(s)': 0,\n",
       " 'has(s)': False,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def vectorisation_texte2(nom):\n",
    "    features = {}\n",
    "    features[\"first_letter\"] = nom[0].lower()\n",
    "    features[\"last_letter\"] = nom[-1].lower()\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count({})\".format(letter)] = nom.lower().count(letter)\n",
    "        features[\"has({})\".format(letter)] = (letter in nom.lower())\n",
    "    return features\n",
    "\n",
    "\n",
    "vectorisation_texte2('carolle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_letter': 'o',\n",
       " 'last_letter': 'e',\n",
       " 'count(a)': 0,\n",
       " 'has(a)': False,\n",
       " 'count(b)': 0,\n",
       " 'has(b)': False,\n",
       " 'count(c)': 0,\n",
       " 'has(c)': False,\n",
       " 'count(d)': 0,\n",
       " 'has(d)': False,\n",
       " 'count(e)': 2,\n",
       " 'has(e)': True,\n",
       " 'count(f)': 0,\n",
       " 'has(f)': False,\n",
       " 'count(g)': 0,\n",
       " 'has(g)': False,\n",
       " 'count(h)': 0,\n",
       " 'has(h)': False,\n",
       " 'count(i)': 1,\n",
       " 'has(i)': True,\n",
       " 'count(j)': 0,\n",
       " 'has(j)': False,\n",
       " 'count(k)': 0,\n",
       " 'has(k)': False,\n",
       " 'count(l)': 0,\n",
       " 'has(l)': False,\n",
       " 'count(m)': 1,\n",
       " 'has(m)': True,\n",
       " 'count(n)': 1,\n",
       " 'has(n)': True,\n",
       " 'count(o)': 1,\n",
       " 'has(o)': True,\n",
       " 'count(p)': 0,\n",
       " 'has(p)': False,\n",
       " 'count(q)': 0,\n",
       " 'has(q)': False,\n",
       " 'count(r)': 0,\n",
       " 'has(r)': False,\n",
       " 'count(s)': 1,\n",
       " 'has(s)': True,\n",
       " 'count(t)': 0,\n",
       " 'has(t)': False,\n",
       " 'count(u)': 0,\n",
       " 'has(u)': False,\n",
       " 'count(v)': 0,\n",
       " 'has(v)': False,\n",
       " 'count(w)': 0,\n",
       " 'has(w)': False,\n",
       " 'count(x)': 0,\n",
       " 'has(x)': False,\n",
       " 'count(y)': 0,\n",
       " 'has(y)': False,\n",
       " 'count(z)': 0,\n",
       " 'has(z)': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorisation_texte2('Onesime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786\n"
     ]
    }
   ],
   "source": [
    "train_set = apply_features(vectorisation_texte2, etiquettes_noms[500:])\n",
    "test_set = apply_features(vectorisation_texte2, etiquettes_noms[:500])\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     35.4 : 1.0\n",
      "             last_letter = 'k'              male : female =     31.5 : 1.0\n",
      "             last_letter = 'p'              male : female =     20.0 : 1.0\n",
      "             last_letter = 'f'              male : female =     16.1 : 1.0\n",
      "             last_letter = 'v'              male : female =     10.6 : 1.0\n",
      "                count(v) = 2              female : male   =      9.1 : 1.0\n",
      "             last_letter = 'd'              male : female =      8.9 : 1.0\n",
      "             last_letter = 'm'              male : female =      8.6 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.2 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.8 : 1.0\n",
      "             last_letter = 'g'              male : female =      5.3 : 1.0\n",
      "             last_letter = 'w'              male : female =      5.1 : 1.0\n",
      "            first_letter = 'w'              male : female =      4.7 : 1.0\n",
      "             last_letter = 'b'              male : female =      4.6 : 1.0\n",
      "                count(w) = 1                male : female =      4.4 : 1.0\n",
      "                  has(w) = True             male : female =      4.3 : 1.0\n",
      "                count(a) = 3              female : male   =      4.3 : 1.0\n",
      "             last_letter = 's'              male : female =      4.1 : 1.0\n",
      "             last_letter = 't'              male : female =      4.0 : 1.0\n",
      "             last_letter = 'z'              male : female =      4.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Répartition des données en training et test pour l'analyse des erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Normalement, nous avons des répartitions de données **entraînement**-**tests**\n",
    "- Parfois, nous pouvons utiliser l'ensemble **development (dev)** pour l'analyse des erreurs et l'ingénierie des fonctionnalités.\n",
    "- Cet ensemble de développement doit être indépendant des ensembles de formation et de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Entraînons maintenant le modèle sur l'**ensemble d'entraînement** et vérifions d'abord les performances du classificateur sur l'ensemble **dev**.\n",
    "- Nous identifions ensuite les erreurs commises par le classificateur dans l'ensemble **dev**.\n",
    "- Nous effectuons une analyse des erreurs pour une amélioration ultérieure.\n",
    "- Nous testons uniquement notre **modèle final** sur l'ensemble de test. (Remarque : l'ensemble de test ne peut être utilisé qu'**une seule**.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.761\n"
     ]
    }
   ],
   "source": [
    "train_names = etiquettes_noms[1500:]\n",
    "devtest_names = etiquettes_noms[500:1500]\n",
    "test_names = etiquettes_noms[:500]\n",
    "\n",
    "train_set = [(vectorisation_texte2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(vectorisation_texte2(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(vectorisation_texte2(n), gender) for (n, gender) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, devtest_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "for (name, tag) in devtest_names:\n",
    "    guess = classifier.classify(vectorisation_texte2(name))\n",
    "    if guess != tag:\n",
    "        errors.append((tag, guess, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('error-analysis.csv', 'w') as f:\n",
    "\n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(['tag', 'guess', 'name'])\n",
    "    write.writerows(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Idéalement, nous pouvons inspecter les erreurs dans une feuille de calcul et proposer de meilleures règles (fonctionnalités) qui pourraient aider à améliorer le classificateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>guess</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Ajay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Charlott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Mattias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Randi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Fortune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Aaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Lorrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Clarke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Gabriele</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Myriam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Stoddard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Garcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Elspeth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Chryste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Terrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Dane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "      <td>Torey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Lennie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Ken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>male</td>\n",
       "      <td>female</td>\n",
       "      <td>Alix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tag   guess      name\n",
       "0      male  female      Ajay\n",
       "1    female    male  Charlott\n",
       "2      male  female   Mattias\n",
       "3      male  female     Randi\n",
       "4    female    male   Fortune\n",
       "5      male  female     Aaron\n",
       "6      male  female    Lorrie\n",
       "7      male  female    Clarke\n",
       "8      male  female  Gabriele\n",
       "9    female    male    Myriam\n",
       "229  female    male  Stoddard\n",
       "230    male  female    Garcia\n",
       "231  female    male   Elspeth\n",
       "232  female    male   Chryste\n",
       "233    male  female  Terrance\n",
       "234    male  female      Dane\n",
       "235  female    male     Torey\n",
       "236    male  female    Lennie\n",
       "237    male  female       Ken\n",
       "238    male  female      Alix"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "## check first and last N rows\n",
    "pd.read_csv('error-analysis.csv').iloc[[*range(10), *range(-10, 0)],]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](../images/confusion-matrix.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Matrice de confusion :\n",
    "     - Les **vrais positifs** sont des éléments pertinents que nous avons correctement identifiés comme pertinents.\n",
    "     - Les **vrais négatifs** sont des éléments non pertinents que nous avons correctement identifiés comme non pertinents.\n",
    "     - Les **faux positifs** (ou erreurs de type I) sont des éléments non pertinents que nous avons identifiés à tort comme pertinents.\n",
    "     - Les **faux négatifs** (ou erreurs de type II) sont des éléments pertinents que nous avons identifiés à tort comme non pertinents.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compte tenu de ces quatre nombres, nous pouvons définir les métriques d'évaluation du modèle suivantes:\n",
    "- **Accuracy** : combien d'éléments ont été correctement classés, -c'est-à-dire., $\\frac{VP + FN}{N}$\n",
    "- **Précision** : combien d'éléments identifiés par le classificateur comme pertinents sont effectivement pertinents, c'est-à-dire., $\\frac{VP}{VP+FP}$.\n",
    "- **Rappel** : combien d'éléments véritablement pertinents ont été identifiés avec succès par le classificateur, c'est-à-dire., $\\frac{VP}{VP+FN}$.\n",
    "- **F-Measure (ou F-Score)** : la moyenne harmonique de la précision et du rappel,c'est-à-dire.:\n",
    "    \n",
    "\n",
    "$$ \n",
    "F= \\frac{(2 × Precision × Recall)}{(Precision + Recall)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ":::{noter}\n",
    "\n",
    "Lorsque nous traitons de distributions de classes déséquilibrées, nous devons prendre en compte les performances de base dans notre évaluation de modèle. Par exemple. si la distribution de la `Class 0` et de la `Class 1` est de 9 : 1, alors un classificateur naïf pourrait tout aussi bien classer tous les cas comme `Class 0`, produisant une performance de haute **précision** (c'est-à-dire Précision = 90 %).\n",
    "\n",
    "Compte tenu de cette base de référence, pour mieux évaluer le classificateur sur un ensemble de données déséquilibré, les **taux de rappel** du classificateur sont probablement plus importants.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:4.2f}'.format(nltk.classify.accuracy(classifier, test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "## Compute the Confusion Matrix\n",
    "t_f = [feature for (feature, label) in test_set]  # features of test set\n",
    "t_l = [label for (feature, label) in test_set]  # labels of test set\n",
    "t_l_pr = [classifier.classify(f) for f in t_f]  # predicted labels of test set\n",
    "cm = nltk.ConfusionMatrix(t_l, t_l_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <49.6%> 10.2% |\n",
      "  male |  11.2% <29.0%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def createCM(classifier, test_set):\n",
    "    t_f = [feature for (feature, label) in test_set]\n",
    "    t_l = [label for (feature, label) in test_set]\n",
    "    t_l_pr = [classifier.classify(f) for f in t_f]\n",
    "    cm = nltk.ConfusionMatrix(t_l, t_l_pr)\n",
    "    print(cm.pretty_format(sort_by_count=True, show_percents=True, truncate=9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <49.6%> 10.2% |\n",
      "  male |  11.2% <29.0%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Nous pouvons également vérifier les performances moyennes de notre modèle en utilisant la méthode de validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.77\n",
      "accuracy: 0.79\n",
      "accuracy: 0.77\n",
      "accuracy: 0.79\n",
      "accuracy: 0.77\n",
      "accuracy: 0.79\n",
      "accuracy: 0.79\n",
      "accuracy: 0.78\n",
      "accuracy: 0.79\n",
      "accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import sklearn.model_selection\n",
    "kf = sklearn.model_selection.KFold(n_splits=10)\n",
    "acc_kf = []  ## accuracy holder\n",
    "\n",
    "## Cross-validation\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = nltk.NaiveBayesClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]])\n",
    "    cur_fold_acc = nltk.classify.util.accuracy(\n",
    "        classifier, train_set[test_index[0]:test_index[len(test_index) - 1]])\n",
    "    acc_kf.append(cur_fold_acc)\n",
    "    print('accuracy:', np.round(cur_fold_acc, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7813193686427171"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_kf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Formation de différents algorithmes de machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Il existe de nombreux algorithmes ML pour les tâches de classification.\n",
    "- Ici, nous allons démontrer quelques classificateurs supplémentaires implémentés dans NLTK, notamment :\n",
    "     - Classificateur d'entropie maximale (régression logistique)\n",
    "     - Classificateur d'arbre de décision\n",
    "- De plus, dans NLTK, nous pouvons également utiliser les méthodes de classification fournies dans `sklearn`, notamment :\n",
    "     - Bayes naïf\n",
    "     - Régression logistique\n",
    "     - Machine à vecteurs de support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Lorsque nous essayons un autre algorithme ML, nous procédons comme suit :\n",
    "     - entraîner le modèle\n",
    "     - vérifier les performances du modèle (matrice de précision et de confusion)\n",
    "     - vérifier les fonctionnalités les plus informatives\n",
    "     - obtenir des performances moyennes en utilisant la validation croisée *k*-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classificateur Maxent\n",
    "\n",
    "souce: https://pro.arcgis.com/fr/pro-app/latest/tool-reference/spatial-statistics/how-presence-only-prediction-works.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- Nota : Maxent est gourmand en mémoire, plus lent et nécessite `numpy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 1s\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.classify import MaxentClassifier\n",
    "classifier_maxent = MaxentClassifier.train(train_set,\n",
    "                                           algorithm='iis',\n",
    "                                           trace=0,\n",
    "                                           max_iter=10000,\n",
    "                                           min_lldelta=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```{remarque}\n",
    "L'algorithme par défaut pour la formation est « iis » (Improved Iterative Scaling). Une autre alternative est `gis` (General Iterative Scaling), qui est plus rapide.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_maxent, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -3.354 last_letter=='a' and label is 'male'\n",
      "  -2.365 last_letter=='k' and label is 'female'\n",
      "  -2.316 last_letter=='f' and label is 'female'\n",
      "  -2.090 count(v)==2 and label is 'male'\n",
      "  -1.552 last_letter=='v' and label is 'female'\n",
      "   1.443 count(j)==2 and label is 'female'\n",
      "  -1.232 last_letter=='m' and label is 'female'\n",
      "  -1.219 last_letter=='d' and label is 'female'\n",
      "  -1.100 last_letter=='o' and label is 'female'\n",
      "  -1.069 last_letter=='z' and label is 'female'\n",
      "  -1.063 last_letter=='i' and label is 'male'\n",
      "   1.055 last_letter=='c' and label is 'male'\n",
      "  -0.881 last_letter=='g' and label is 'female'\n",
      "  -0.875 last_letter=='r' and label is 'female'\n",
      "  -0.867 count(y)==2 and label is 'male'\n",
      "  -0.858 last_letter=='j' and label is 'female'\n",
      "   0.858 count(g)==3 and label is 'male'\n",
      "  -0.849 count(e)==4 and label is 'male'\n",
      "   0.831 last_letter=='p' and label is 'male'\n",
      "  -0.771 count(e)==3 and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "classifier_maxent.show_most_informative_features(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <53.0%>  6.8% |\n",
      "  male |  12.2% <28.0%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier_maxent, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6583850931677019\n",
      "accuracy: 0.7096273291925466\n",
      "accuracy: 0.6816770186335404\n",
      "accuracy: 0.6940993788819876\n",
      "accuracy: 0.6811819595645412\n",
      "accuracy: 0.6827371695178849\n",
      "accuracy: 0.6734059097978227\n",
      "accuracy: 0.7216174183514774\n",
      "accuracy: 0.702954898911353\n",
      "accuracy: 0.6982892690513219\n",
      "CPU times: total: 2min 29s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = MaxentClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]],\n",
    "        algorithm='gis',\n",
    "        trace=0,\n",
    "        max_iter=100,\n",
    "        min_lldelta=0.01) ## set smaller value for `min_lldelta`\n",
    "    print(\n",
    "        'accuracy:',\n",
    "        nltk.classify.util.accuracy(\n",
    "            classifier,\n",
    "            train_set[test_index[0]:test_index[len(test_index) - 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Parameters:\n",
    "    - `binary`: whether the features are binary\n",
    "    - `entropy_cutoff`: a value used during tree refinement process\n",
    "        - entropy = 1 -> high-level uncertainty\n",
    "        - entropy = 0 -> perfect model prediction\n",
    "    - `depth_cutoff`: to control the depth of the tree\n",
    "    - `support_cutoff`: the minimum number of instances that are required to make a decision about a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12.8 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from nltk.classify import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier.train(train_set,\n",
    "                                             binary=True,\n",
    "                                             entropy_cutoff=0.7,\n",
    "                                             depth_cutoff=5,\n",
    "                                             support_cutoff=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.732"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_dt, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       |      f        |\n",
      "       |      e        |\n",
      "       |      m      m |\n",
      "       |      a      a |\n",
      "       |      l      l |\n",
      "       |      e      e |\n",
      "-------+---------------+\n",
      "female | <57.6%>  2.2% |\n",
      "  male |  24.6% <15.6%>|\n",
      "-------+---------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "createCM(classifier_dt, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6863354037267081\n",
      "accuracy: 0.718944099378882\n",
      "accuracy: 0.7018633540372671\n",
      "accuracy: 0.7127329192546584\n",
      "accuracy: 0.7169517884914464\n",
      "accuracy: 0.6967340590979783\n",
      "accuracy: 0.6998444790046656\n",
      "accuracy: 0.7542768273716952\n",
      "accuracy: 0.7325038880248833\n",
      "accuracy: 0.7325038880248833\n",
      "CPU times: total: 2min 14s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for train_index, test_index in kf.split(train_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    classifier = DecisionTreeClassifier.train(\n",
    "        train_set[train_index[0]:train_index[len(train_index) - 1]],\n",
    "        binary=True,\n",
    "        entropy_cutoff=0.7,\n",
    "        depth_cutoff=5,\n",
    "        support_cutoff=5)\n",
    "    print(\n",
    "        'accuracy:',\n",
    "        nltk.classify.util.accuracy(\n",
    "            classifier,\n",
    "            train_set[test_index[0]:test_index[len(test_index) - 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# `sklearn` Classificateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `sklearn` est un module très utile pour le machine learning. Nous parlerons davantage de ce module dans la suite de nos tutoriels.\n",
    "- Ce package fournit beaucoup plus d'algorithmes ML pour les tâches de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes naïfs dans `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(MultinomialNB())>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "sk_classifier = SklearnClassifier(MultinomialNB())\n",
    "sk_classifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.784"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Régression logistique dans `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_classifier = SklearnClassifier(LogisticRegression(max_iter=500))\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine à vecteurs de support dans `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `sklearn` fournit plusieurs implémentations pour les machines à vecteurs de support.\n",
    "- Veuillez consulter sa documentation pour plus de détails: [Support Vector Machine](https://scikit-learn.org/stable/modules/svm.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.816"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sk_classifier = SklearnClassifier(SVC())\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Onesime Mb\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.802"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "sk_classifier = SklearnClassifier(LinearSVC(max_iter=2000))\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "sk_classifier = SklearnClassifier(NuSVC())\n",
    "sk_classifier.train(train_set)\n",
    "nltk.classify.accuracy(sk_classifier, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Travaux à faire plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- L'ingénierie des fonctionnalités est cruciale pour le processus d'apprentissage automatique.\n",
    "- La qualité de la vectorisation du texte détermine presque en grande partie les performances du classificateur.\n",
    "- Chaque algorithme ML nécessite de nombreux paramètres d'**hyperparamètres**, ce qui peut avoir un impact substantiel sur les performances du modèle.\n",
    "- Nous avons besoin d'un moyen plus **systématique** pour trouver les combinaisons optimales d'hyperparamètres pour un algorithme ML donné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Contacts\n",
    "\n",
    "- mbonesime@gmai.com\n",
    "- mbulayi.onesime@unikin.ac.cd"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "706px",
    "left": "1519.67px",
    "top": "85px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
